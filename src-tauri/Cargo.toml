[package]
name = "careerbench"
version = "0.1.0"
description = "AI-powered job search management desktop application"
authors = ["CareerBench Team"]
license = ""
repository = ""
edition = "2021"

[lib]
name = "careerbench"
path = "src/lib.rs"

[build-dependencies]
tauri-build = { version = "2.0", features = [] }

[dependencies]
tauri = { version = "2.0", features = [] }
tauri-plugin-shell = "2.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
rusqlite = { version = "0.31", features = ["bundled"] }
sha2 = { version = "0.10", features = ["std"] }
chrono = { version = "0.4", features = ["serde"] }
tokio = { version = "1", features = ["full"] }
reqwest = { version = "0.12", features = ["json"] }
async-trait = "0.1"
# Local model inference - using llama-cpp-sys-3 for GGUF model support
llama-cpp-sys-3 = "0.5"
num_cpus = "1.16"

[features]
default = ["custom-protocol"]
custom-protocol = ["tauri/custom-protocol"]

[dev-dependencies]
tempfile = "3.10"

